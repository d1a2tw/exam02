{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE2405_Exam_2_Part_2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1ebUOX16FD",
        "colab_type": "text"
      },
      "source": [
        "# EE2405 Embedded System Lab Exam #2 Part 2\n",
        "\n",
        "**Please click on \"Open in playground\" at the upper-left corner to create a copy for you.**\n",
        "\n",
        "---\n",
        "\n",
        "**Please fill in correct statements in the right of the codes to finish the scripts.**  \n",
        "Data sample is generated with a quadratic function and we will train a regression model to fit the data.  \n",
        "And we convert and interpret the trained model with a Tensorflow lite APIs.\n",
        "\n",
        "You can run the script again after you fill all the blank to check the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "The Method to Download the Jupyter Notebook:  \n",
        "File > Download .ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3FqFF1zRJW",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhRpD2SsyQrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztOxOMy0eUB",
        "colab_type": "text"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgApv0fcwU3I",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "4064348f-cb29-4071-c8f1-31c764772886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "############################################################\n",
        "#@markdown Please fill in the number of samples (the sample should be large enough, but not too large for computation).\n",
        "SAMPLES =  1000#@param {type:\"number\"}\n",
        "############################################################\n",
        "\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in your student id, which is the random seed.\n",
        "student_id = 105061151 #@param {type:\"number\"}\n",
        "np.random.seed(student_id)\n",
        "############################################################\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers\n",
        "# in the range from 0 to 10\n",
        "x_values = np.random.uniform(low=0, high=10, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in the statement to generate `y_values` with a quadratic function `y = x^2-5x+1`?\n",
        "script = \"y_values=x_values\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "\n",
        "# Plot our data.\n",
        "# The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGVnrxG10nHh",
        "colab_type": "text"
      },
      "source": [
        "## Add some noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7y-_3_x-Lz",
        "colab_type": "code",
        "outputId": "6ed7df14-53ac-41d2-9a63-09e9454cb2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4ZI4Wv4B_y",
        "colab_type": "text"
      },
      "source": [
        "## Split our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zguEyz393e",
        "colab_type": "code",
        "outputId": "8e5d5152-7cbf-4c1b-9cc7-69838d5123a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggfIuHp4PCy",
        "colab_type": "text"
      },
      "source": [
        "## Design a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty9IWi-4QhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeLOUmx4VY7",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiV9Aee4ZTb",
        "colab_type": "code",
        "outputId": "0e8c0f0b-b355-4bcb-a1dc-0ad87334bd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "          validation_data=(x_validate, y_validate))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 26.3240 - mae: 4.3274 - val_loss: 17.8947 - val_mae: 3.7178\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8548 - mae: 2.5787 - val_loss: 4.2381 - val_mae: 1.7558\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4601 - mae: 0.9143 - val_loss: 0.1672 - val_mae: 0.3391\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0820 - mae: 0.2359 - val_loss: 0.0509 - val_mae: 0.1826\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.1491 - val_loss: 0.0224 - val_mae: 0.1182\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0802 - val_loss: 0.0071 - val_mae: 0.0560\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0463 - val_loss: 0.0051 - val_mae: 0.0556\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0388 - val_loss: 0.0020 - val_mae: 0.0172\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0349 - val_loss: 0.0033 - val_mae: 0.0436\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0329 - val_loss: 0.0097 - val_mae: 0.0922\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0185\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0254 - val_loss: 4.4225e-04 - val_mae: 0.0101\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0274 - val_loss: 5.2517e-04 - val_mae: 0.0182\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0010 - val_mae: 0.0299\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 2.9365e-04 - val_mae: 0.0139\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0105 - val_mae: 0.0909\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0251 - val_loss: 0.0015 - val_mae: 0.0337\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0251 - val_loss: 0.0103 - val_mae: 0.0925\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0223 - val_loss: 0.0030 - val_mae: 0.0497\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0311\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 2.1766e-05 - val_mae: 0.0040\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0252 - val_loss: 8.2579e-05 - val_mae: 0.0071\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 0.0026 - val_mae: 0.0461\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0380\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 2.3901e-04 - val_mae: 0.0133\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 2.0486e-05 - val_mae: 0.0035\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0030 - val_mae: 0.0499\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 5.3024e-04 - val_mae: 0.0190\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 0.0035 - val_mae: 0.0531\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 0.0012 - val_mae: 0.0318\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 6.6531e-04 - val_mae: 0.0237\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 2.3072e-05 - val_mae: 0.0039\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0237 - val_loss: 1.3761e-05 - val_mae: 0.0029\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 3.4649e-05 - val_mae: 0.0054\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 6.8662e-05 - val_mae: 0.0071\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 2.7282e-04 - val_mae: 0.0138\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0226 - val_loss: 1.0796e-06 - val_mae: 4.6429e-04\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0125 - val_loss: 0.0029 - val_mae: 0.0482\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0210 - val_loss: 1.6550e-05 - val_mae: 0.0032\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0109 - val_mae: 0.0937\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 2.7288e-05 - val_mae: 0.0046\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 2.4818e-04 - val_mae: 0.0136\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 2.9970e-06 - val_mae: 0.0011\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0212 - val_loss: 6.3541e-04 - val_mae: 0.0234\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 7.0333e-04 - val_mae: 0.0227\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0887e-04 - mae: 0.0161 - val_loss: 0.0013 - val_mae: 0.0326\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0199 - val_loss: 6.6536e-06 - val_mae: 0.0025\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0218 - val_loss: 1.9239e-05 - val_mae: 0.0024\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0137 - val_loss: 0.0070 - val_mae: 0.0751\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0161 - val_loss: 8.7053e-06 - val_mae: 0.0011\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0188 - val_loss: 6.4326e-04 - val_mae: 0.0231\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.8382e-04 - mae: 0.0086 - val_loss: 5.8293e-04 - val_mae: 0.0219\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0188 - val_loss: 0.0013 - val_mae: 0.0321\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0232 - val_loss: 1.4109e-05 - val_mae: 0.0037\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 5.6236e-07 - val_mae: 6.1981e-04\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0220 - val_loss: 4.3336e-04 - val_mae: 0.0187\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0205 - val_loss: 0.0060 - val_mae: 0.0701\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0236 - val_loss: 0.0020 - val_mae: 0.0411\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0024 - val_mae: 0.0447\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0308\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.5547e-04 - mae: 0.0155 - val_loss: 3.0456e-04 - val_mae: 0.0154\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 4.1379e-04 - val_mae: 0.0182\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0209 - val_loss: 4.0397e-04 - val_mae: 0.0176\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 1.7441e-06 - val_mae: 5.8812e-04\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 2.0663e-06 - val_mae: 0.0012\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 5.8640e-04 - val_mae: 0.0219\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6995e-04 - mae: 0.0139 - val_loss: 0.0018 - val_mae: 0.0386\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 0.0061 - val_mae: 0.0702\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 0.0145 - val_mae: 0.1084\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0231 - val_loss: 1.2420e-04 - val_mae: 0.0104\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 0.0060 - val_mae: 0.0689\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0206 - val_loss: 3.3770e-05 - val_mae: 0.0052\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3150e-04 - mae: 0.0123 - val_loss: 1.0682e-04 - val_mae: 0.0094\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 3.1605e-04 - val_mae: 0.0165\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0246 - val_loss: 9.0374e-06 - val_mae: 0.0014\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 2.1993e-06 - val_mae: 9.6479e-04\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 7.7500e-07 - val_mae: 6.6445e-04\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0192 - val_loss: 2.6435e-05 - val_mae: 0.0050\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 2.2966e-05 - val_mae: 0.0042\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0025 - val_mae: 0.0450\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 2.9796e-06 - val_mae: 9.6859e-04\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3021e-04 - mae: 0.0141 - val_loss: 1.0426e-05 - val_mae: 0.0022\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 6.1169e-04 - val_mae: 0.0223\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 1.4298e-04 - val_mae: 0.0109\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 1.4027e-05 - val_mae: 0.0035\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 7.1603e-06 - val_mae: 0.0022\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5705e-04 - mae: 0.0095 - val_loss: 1.7749e-05 - val_mae: 0.0037\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 3.1138e-06 - val_mae: 0.0014\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 1.8488e-05 - val_mae: 0.0041\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 3.1849e-05 - val_mae: 0.0034\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 4.3046e-04 - val_mae: 0.0191\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8766e-04 - mae: 0.0195 - val_loss: 1.5148e-04 - val_mae: 0.0112\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0178 - val_loss: 5.9164e-06 - val_mae: 0.0022\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 1.2698e-06 - val_mae: 7.7299e-04\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 0.0021 - val_mae: 0.0412\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0228 - val_loss: 2.7467e-05 - val_mae: 0.0018\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0166 - val_loss: 2.1729e-06 - val_mae: 8.7150e-04\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.8116e-04 - mae: 0.0115 - val_loss: 0.0115 - val_mae: 0.0966\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0200 - val_loss: 1.2953e-04 - val_mae: 0.0107\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 2.2663e-04 - val_mae: 0.0140\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0015 - val_mae: 0.0362\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0045 - val_mae: 0.0606\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 6.6470e-07 - val_mae: 6.7881e-04\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 1.1290e-05 - val_mae: 0.0027\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0193 - val_loss: 0.0017 - val_mae: 0.0371\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 1.8237e-05 - val_mae: 0.0038\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0199 - val_loss: 3.7803e-06 - val_mae: 0.0016\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0191 - val_loss: 1.2465e-06 - val_mae: 8.0636e-04\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 3.1959e-05 - val_mae: 0.0047\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0203 - val_loss: 0.0028 - val_mae: 0.0483\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0156 - val_loss: 1.0185e-06 - val_mae: 2.8427e-04\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0149 - val_loss: 9.0388e-04 - val_mae: 0.0273\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 3.7142e-05 - val_mae: 0.0056\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 1.0104e-04 - val_mae: 0.0086\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 9.5194e-04 - val_mae: 0.0279\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0017 - val_mae: 0.0374\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0202 - val_loss: 1.3116e-04 - val_mae: 0.0108\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 0.0129 - val_mae: 0.1023\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0129 - val_loss: 1.3216e-05 - val_mae: 0.0034\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 0.0119 - val_mae: 0.0977\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0241 - val_loss: 4.9867e-07 - val_mae: 4.8446e-04\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 9.2879e-05 - val_mae: 0.0087\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0212 - val_loss: 3.2517e-04 - val_mae: 0.0158\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.6176e-04 - mae: 0.0101 - val_loss: 3.6601e-05 - val_mae: 0.0058\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0222 - val_loss: 0.0115 - val_mae: 0.0957\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 8.6654e-06 - val_mae: 0.0026\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 1.3774e-05 - val_mae: 0.0034\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 1.9712e-06 - val_mae: 0.0011\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0199 - val_loss: 0.0038 - val_mae: 0.0560\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0015 - val_mae: 0.0348\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0013 - val_mae: 0.0333\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 3.0522e-06 - val_mae: 0.0011\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 5.6084e-05 - val_mae: 0.0067\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0179 - val_loss: 0.0084 - val_mae: 0.0819\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 2.4027e-05 - val_mae: 0.0031\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 6.2748e-05 - val_mae: 0.0069\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 2.3523e-06 - val_mae: 0.0012\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 1.5707e-05 - val_mae: 0.0033\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 2.2855e-04 - val_mae: 0.0138\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0224 - val_loss: 1.4756e-06 - val_mae: 9.9791e-04\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0173 - val_loss: 1.2865e-04 - val_mae: 0.0105\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9664e-04 - mae: 0.0170 - val_loss: 0.0027 - val_mae: 0.0469\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0106 - val_mae: 0.0924\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 0.0023 - val_mae: 0.0437\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0230 - val_loss: 0.0040 - val_mae: 0.0566\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7969e-04 - mae: 0.0184 - val_loss: 0.0014 - val_mae: 0.0319\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 6.7896e-04 - val_mae: 0.0237\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.0052 - val_mae: 0.0654\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 1.3328e-04 - val_mae: 0.0105\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 4.6551e-04 - val_mae: 0.0202\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 2.8811e-05 - val_mae: 0.0045\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0221 - val_loss: 1.9591e-04 - val_mae: 0.0119\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0170 - val_loss: 0.0053 - val_mae: 0.0652\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0147 - val_loss: 6.8678e-04 - val_mae: 0.0236\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 2.7229e-04 - val_mae: 0.0152\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 9.1799e-06 - val_mae: 0.0020\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 4.5809e-06 - val_mae: 0.0015\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 9.3614e-04 - val_mae: 0.0276\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 1.2209e-05 - val_mae: 0.0027\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8229e-04 - mae: 0.0169 - val_loss: 4.8503e-04 - val_mae: 0.0202\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0140 - val_mae: 0.1065\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0141 - val_loss: 5.3549e-05 - val_mae: 0.0065\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 8.8080e-05 - val_mae: 0.0086\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 2.1724e-06 - val_mae: 0.0013\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 1.3291e-05 - val_mae: 0.0013\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0150 - val_loss: 0.0024 - val_mae: 0.0445\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3144e-04 - mae: 0.0133 - val_loss: 2.0262e-06 - val_mae: 8.0022e-04\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 0.0033 - val_mae: 0.0517\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 9.6762e-04 - val_mae: 0.0275\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0162 - val_loss: 4.3859e-04 - val_mae: 0.0188\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 1.4463e-06 - val_mae: 0.0010\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.9155e-04 - mae: 0.0115 - val_loss: 0.0044 - val_mae: 0.0595\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 6.8893e-04 - val_mae: 0.0233\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4522e-04 - mae: 0.0140 - val_loss: 7.5614e-05 - val_mae: 0.0079\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 1.6120e-05 - val_mae: 0.0025\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 4.4069e-05 - val_mae: 0.0061\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 6.5268e-07 - val_mae: 5.2124e-04\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8722e-04 - mae: 0.0125 - val_loss: 5.6101e-04 - val_mae: 0.0221\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0186 - val_loss: 3.1678e-05 - val_mae: 0.0050\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0179 - val_loss: 9.5758e-05 - val_mae: 0.0087\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0206 - val_loss: 2.5791e-07 - val_mae: 1.6026e-04\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7934e-04 - mae: 0.0142 - val_loss: 0.0012 - val_mae: 0.0310\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 4.3964e-06 - val_mae: 0.0020\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0026 - val_mae: 0.0455\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 8.5977e-06 - val_mae: 0.0028\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0153 - val_loss: 7.7806e-05 - val_mae: 0.0084\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 4.5404e-05 - val_mae: 0.0060\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0305\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 5.3370e-05 - val_mae: 0.0060\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5119e-04 - mae: 0.0212 - val_loss: 1.9175e-05 - val_mae: 0.0039\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 2.0624e-04 - val_mae: 0.0123\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0176 - val_loss: 0.0046 - val_mae: 0.0611\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2512e-04 - mae: 0.0151 - val_loss: 0.0094 - val_mae: 0.0873\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 1.6608e-04 - val_mae: 0.0114\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 3.0303e-05 - val_mae: 0.0046\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8771e-04 - mae: 0.0176 - val_loss: 2.9592e-05 - val_mae: 0.0035\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 6.5699e-05 - val_mae: 0.0077\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 3.0587e-05 - val_mae: 0.0053\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 1.0912e-06 - val_mae: 7.6146e-04\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 2.5443e-05 - val_mae: 0.0044\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4474e-04 - mae: 0.0214 - val_loss: 2.7370e-04 - val_mae: 0.0154\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4964e-04 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0329\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0209 - val_loss: 0.0013 - val_mae: 0.0328\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0214 - val_loss: 2.6830e-04 - val_mae: 0.0147\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 2.5702e-04 - val_mae: 0.0144\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 0.0102 - val_mae: 0.0908\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 0.0140 - val_mae: 0.1066\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0125 - val_loss: 8.1333e-06 - val_mae: 0.0026\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0071 - val_mae: 0.0758\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8248e-04 - mae: 0.0183 - val_loss: 3.7532e-06 - val_mae: 0.0019\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 5.4368e-04 - val_mae: 0.0208\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 3.3564e-04 - val_mae: 0.0163\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 1.7658e-04 - val_mae: 0.0114\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 3.4942e-05 - val_mae: 0.0057\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7971e-04 - mae: 0.0241 - val_loss: 9.8354e-05 - val_mae: 0.0082\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0212 - val_loss: 1.9824e-06 - val_mae: 0.0012\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0073 - val_mae: 0.0762\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 0.0049 - val_mae: 0.0618\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9447e-04 - mae: 0.0157 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 1.4917e-06 - val_mae: 0.0010\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0235 - val_loss: 0.0015 - val_mae: 0.0351\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2513e-04 - mae: 0.0097 - val_loss: 5.2923e-06 - val_mae: 0.0019\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 1.4802e-04 - val_mae: 0.0110\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 0.0152 - val_mae: 0.1106\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0148 - val_loss: 7.4589e-05 - val_mae: 0.0083\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 6.7005e-06 - val_mae: 0.0023\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 1.7592e-06 - val_mae: 0.0011\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 0.0010 - val_mae: 0.0289\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5979e-04 - mae: 0.0226 - val_loss: 3.5461e-05 - val_mae: 0.0050\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0203 - val_loss: 8.6492e-07 - val_mae: 8.4763e-04\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 4.9523e-05 - val_mae: 0.0069\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 6.4098e-05 - val_mae: 0.0070\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 1.9491e-05 - val_mae: 0.0028\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 2.3337e-04 - val_mae: 0.0140\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 1.2110e-04 - val_mae: 0.0096\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 4.6403e-06 - val_mae: 0.0019\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0159 - val_loss: 7.2428e-07 - val_mae: 6.0891e-04\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3773e-04 - mae: 0.0174 - val_loss: 1.8500e-05 - val_mae: 0.0041\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0210 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8371e-04 - mae: 0.0151 - val_loss: 2.1855e-04 - val_mae: 0.0134\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 5.8666e-04 - val_mae: 0.0216\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 3.2563e-06 - val_mae: 4.5924e-04\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.4741e-04 - mae: 0.0100 - val_loss: 0.0144 - val_mae: 0.1080\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0145 - val_loss: 4.2812e-05 - val_mae: 0.0058\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 2.7105e-05 - val_mae: 0.0045\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0195 - val_loss: 6.3867e-06 - val_mae: 0.0021\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3942e-04 - mae: 0.0170 - val_loss: 2.4974e-06 - val_mae: 0.0013\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 1.0202e-05 - val_mae: 6.2323e-04\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0312\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 7.8293e-07 - val_mae: 6.9922e-04\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 2.5554e-04 - val_mae: 0.0143\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8361e-04 - mae: 0.0214 - val_loss: 0.0047 - val_mae: 0.0623\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 1.5354e-05 - val_mae: 0.0034\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2044e-04 - mae: 0.0187 - val_loss: 0.0136 - val_mae: 0.1050\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 0.0047 - val_mae: 0.0619\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0233 - val_loss: 0.0084 - val_mae: 0.0827\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 4.9381e-06 - val_mae: 0.0018\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 7.9925e-07 - val_mae: 8.4391e-04\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9438e-04 - mae: 0.0184 - val_loss: 2.2668e-05 - val_mae: 0.0042\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0206 - val_loss: 5.2554e-07 - val_mae: 1.3586e-04\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.4619e-04 - mae: 0.0113 - val_loss: 0.0017 - val_mae: 0.0378\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 6.4031e-07 - val_mae: 6.5599e-04\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 1.5190e-06 - val_mae: 9.8928e-04\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0143 - val_loss: 1.4624e-05 - val_mae: 0.0036\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0207 - val_loss: 4.0698e-06 - val_mae: 0.0017\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 8.4755e-05 - val_mae: 0.0083\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0048 - val_mae: 0.0628\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0207 - val_loss: 6.2863e-04 - val_mae: 0.0226\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 9.6355e-06 - val_mae: 0.0025\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2255e-04 - mae: 0.0123 - val_loss: 0.0022 - val_mae: 0.0426\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0193 - val_loss: 9.8525e-04 - val_mae: 0.0285\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0054 - val_mae: 0.0661\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0293\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 1.4643e-04 - val_mae: 0.0113\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.9097e-04 - mae: 0.0126 - val_loss: 0.0075 - val_mae: 0.0777\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 9.4385e-05 - val_mae: 0.0092\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 3.5837e-05 - val_mae: 0.0055\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0187 - val_loss: 2.1493e-04 - val_mae: 0.0133\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 3.9313e-04 - val_mae: 0.0177\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0286\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 1.8276e-06 - val_mae: 9.6533e-04\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0161 - val_loss: 5.7827e-07 - val_mae: 6.3368e-04\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0072 - val_mae: 0.0761\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2774e-04 - mae: 0.0128 - val_loss: 2.1208e-04 - val_mae: 0.0133\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 1.4218e-05 - val_mae: 0.0035\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 2.7689e-05 - val_mae: 0.0044\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 7.3655e-04 - val_mae: 0.0246\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 5.0533e-06 - val_mae: 0.0022\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8027e-04 - mae: 0.0093 - val_loss: 6.6200e-05 - val_mae: 0.0068\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 0.0052 - val_mae: 0.0650\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 1.3987e-05 - val_mae: 0.0037\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.5619e-04 - mae: 0.0141 - val_loss: 1.7264e-05 - val_mae: 0.0035\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 6.3875e-05 - val_mae: 0.0075\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7359e-04 - mae: 0.0189 - val_loss: 1.7255e-05 - val_mae: 0.0037\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 2.9705e-04 - val_mae: 0.0159\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6068e-04 - mae: 0.0139 - val_loss: 0.0062 - val_mae: 0.0715\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 1.6249e-04 - val_mae: 0.0109\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 1.1572e-05 - val_mae: 0.0034\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7880e-04 - mae: 0.0188 - val_loss: 3.7899e-04 - val_mae: 0.0176\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 7.2271e-04 - val_mae: 0.0245\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3314e-04 - mae: 0.0159 - val_loss: 0.0036 - val_mae: 0.0541\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 0.0093 - val_mae: 0.0865\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0209 - val_loss: 1.4965e-05 - val_mae: 0.0031\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 1.3750e-04 - val_mae: 0.0104\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6763e-04 - mae: 0.0104 - val_loss: 5.9799e-05 - val_mae: 0.0068\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 3.1787e-05 - val_mae: 0.0050\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 3.2392e-07 - val_mae: 4.7849e-04\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 0.0078 - val_mae: 0.0791\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2484e-04 - mae: 0.0113 - val_loss: 8.2579e-04 - val_mae: 0.0258\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0365\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5785e-04 - mae: 0.0179 - val_loss: 0.0013 - val_mae: 0.0331\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6106e-04 - mae: 0.0150 - val_loss: 1.9789e-04 - val_mae: 0.0129\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 2.0736e-05 - val_mae: 0.0044\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0225 - val_loss: 4.6166e-06 - val_mae: 9.6261e-04\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0019 - val_mae: 0.0397\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1162e-04 - mae: 0.0183 - val_loss: 6.2685e-06 - val_mae: 0.0011\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 4.2826e-06 - val_mae: 0.0019\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9076e-04 - mae: 0.0174 - val_loss: 2.6090e-04 - val_mae: 0.0147\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 6.8438e-05 - val_mae: 0.0074\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 3.3561e-04 - val_mae: 0.0167\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 0.0022 - val_mae: 0.0426\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4859e-04 - mae: 0.0176 - val_loss: 1.0468e-04 - val_mae: 0.0093\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 1.3261e-04 - val_mae: 0.0103\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 1.0128e-05 - val_mae: 0.0014\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 2.2883e-06 - val_mae: 0.0012\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0678e-04 - mae: 0.0100 - val_loss: 0.0018 - val_mae: 0.0382\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0235 - val_loss: 0.0040 - val_mae: 0.0568\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9900e-04 - mae: 0.0161 - val_loss: 0.0012 - val_mae: 0.0314\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5817e-04 - mae: 0.0208 - val_loss: 1.9724e-06 - val_mae: 0.0012\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 2.3598e-05 - val_mae: 0.0042\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 1.5551e-07 - val_mae: 3.2367e-04\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0147 - val_loss: 6.1915e-04 - val_mae: 0.0223\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6214e-04 - mae: 0.0195 - val_loss: 1.1941e-04 - val_mae: 0.0099\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 1.0218e-05 - val_mae: 0.0025\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8295e-04 - mae: 0.0170 - val_loss: 2.6950e-05 - val_mae: 0.0046\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0155 - val_loss: 2.3233e-05 - val_mae: 0.0016\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.8866e-04 - mae: 0.0131 - val_loss: 0.0068 - val_mae: 0.0744\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0230 - val_loss: 1.7297e-04 - val_mae: 0.0127\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0146 - val_loss: 1.2266e-04 - val_mae: 0.0103\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6812e-04 - mae: 0.0173 - val_loss: 1.5946e-05 - val_mae: 0.0027\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4404e-04 - mae: 0.0172 - val_loss: 1.4843e-06 - val_mae: 8.2913e-04\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 8.7368e-07 - val_mae: 7.6513e-04\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0301\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0180 - val_loss: 9.0352e-05 - val_mae: 0.0086\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.6609e-04 - mae: 0.0099 - val_loss: 0.0011 - val_mae: 0.0293\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0165 - val_loss: 3.2265e-05 - val_mae: 0.0050\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 1.9922e-04 - val_mae: 0.0123\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 1.8406e-04 - val_mae: 0.0128\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 3.8593e-04 - val_mae: 0.0181\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.9968e-04 - mae: 0.0192 - val_loss: 4.3538e-04 - val_mae: 0.0188\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 1.2881e-04 - val_mae: 0.0105\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 4.4930e-04 - val_mae: 0.0198\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9745e-04 - mae: 0.0185 - val_loss: 7.2989e-04 - val_mae: 0.0250\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 2.0360e-06 - val_mae: 7.9337e-04\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0173 - val_loss: 9.1386e-04 - val_mae: 0.0272\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6096e-04 - mae: 0.0219 - val_loss: 3.9337e-05 - val_mae: 0.0054\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 3.5147e-06 - val_mae: 5.2034e-04\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1188e-04 - mae: 0.0173 - val_loss: 1.1393e-05 - val_mae: 0.0025\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 9.0833e-05 - val_mae: 0.0082\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9935e-04 - mae: 0.0199 - val_loss: 0.0042 - val_mae: 0.0578\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 8.8009e-05 - val_mae: 0.0086\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0199 - val_loss: 7.3168e-07 - val_mae: 4.0098e-04\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4667e-04 - mae: 0.0108 - val_loss: 0.0121 - val_mae: 0.0990\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 8.3913e-04 - val_mae: 0.0257\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 1.3890e-04 - val_mae: 0.0108\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.1237e-04 - mae: 0.0106 - val_loss: 0.0040 - val_mae: 0.0571\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 3.0398e-05 - val_mae: 0.0050\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.7616e-07 - val_mae: 7.5348e-04\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 6.8216e-04 - val_mae: 0.0229\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5263e-04 - mae: 0.0104 - val_loss: 4.3780e-04 - val_mae: 0.0192\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0194 - val_loss: 2.2230e-04 - val_mae: 0.0135\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9539e-04 - mae: 0.0156 - val_loss: 8.8151e-07 - val_mae: 6.3275e-04\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7442e-04 - mae: 0.0135 - val_loss: 3.5727e-05 - val_mae: 0.0055\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 1.0768e-04 - val_mae: 0.0096\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 5.3150e-07 - val_mae: 5.8937e-04\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 0.0010 - val_mae: 0.0295\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1061e-04 - mae: 0.0196 - val_loss: 3.9499e-04 - val_mae: 0.0181\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 3.3831e-04 - val_mae: 0.0166\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 3.0750e-04 - val_mae: 0.0158\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0303\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0211 - val_loss: 3.7403e-07 - val_mae: 5.0085e-04\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 1.0050e-05 - val_mae: 0.0025\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 8.0493e-07 - val_mae: 2.6711e-04\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 1.9911e-04 - val_mae: 0.0132\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 5.1036e-05 - val_mae: 0.0062\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0170 - val_loss: 1.8505e-05 - val_mae: 7.4040e-04\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6474e-04 - mae: 0.0118 - val_loss: 0.0058 - val_mae: 0.0686\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 8.7840e-07 - val_mae: 2.2195e-04\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0177 - val_loss: 2.6195e-05 - val_mae: 0.0043\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.9008e-04 - mae: 0.0104 - val_loss: 1.1367e-04 - val_mae: 0.0096\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0154 - val_loss: 3.8742e-04 - val_mae: 0.0180\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 5.8254e-06 - val_mae: 0.0024\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6797e-04 - mae: 0.0173 - val_loss: 1.4138e-06 - val_mae: 7.9668e-04\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 1.2877e-06 - val_mae: 9.1977e-04\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 2.5935e-06 - val_mae: 0.0013\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3996e-04 - mae: 0.0148 - val_loss: 9.2830e-04 - val_mae: 0.0271\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 3.6189e-07 - val_mae: 5.6967e-04\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0007e-04 - mae: 0.0114 - val_loss: 2.8596e-05 - val_mae: 0.0034\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 3.6833e-05 - val_mae: 0.0057\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 2.7151e-05 - val_mae: 0.0025\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 4.9069e-06 - val_mae: 5.7263e-04\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 6.9309e-04 - mae: 0.0103 - val_loss: 3.2536e-05 - val_mae: 0.0048\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 2.2531e-04 - val_mae: 0.0138\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.8519e-04 - mae: 0.0209 - val_loss: 9.5858e-05 - val_mae: 0.0086\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0340\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.6127e-04 - mae: 0.0191 - val_loss: 9.2788e-04 - val_mae: 0.0273\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 3.5574e-05 - val_mae: 0.0059\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0189 - val_loss: 4.7712e-07 - val_mae: 5.9027e-04\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5819e-04 - mae: 0.0147 - val_loss: 1.2813e-06 - val_mae: 0.0011\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 7.6218e-05 - val_mae: 0.0071\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0207 - val_loss: 1.2202e-04 - val_mae: 0.0092\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 1.1554e-06 - val_mae: 9.9013e-04\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.8350e-04 - mae: 0.0134 - val_loss: 3.4446e-04 - val_mae: 0.0167\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0192 - val_loss: 1.7805e-06 - val_mae: 5.7692e-04\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7180e-04 - mae: 0.0183 - val_loss: 0.0065 - val_mae: 0.0722\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 1.9677e-04 - val_mae: 0.0120\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0183 - val_loss: 0.0188 - val_mae: 0.1230\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0180 - val_loss: 1.0210e-04 - val_mae: 0.0086\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 2.8220e-04 - val_mae: 0.0150\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7876e-04 - mae: 0.0187 - val_loss: 3.8935e-04 - val_mae: 0.0176\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0301 - val_loss: 1.0983e-06 - val_mae: 8.8345e-04\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 6.9567e-04 - val_mae: 0.0241\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2926e-04 - mae: 0.0124 - val_loss: 2.1869e-04 - val_mae: 0.0138\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0226 - val_loss: 4.1286e-04 - val_mae: 0.0190\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8548e-04 - mae: 0.0119 - val_loss: 3.2419e-05 - val_mae: 0.0047\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0163 - val_loss: 7.0901e-05 - val_mae: 0.0078\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 1.3692e-05 - val_mae: 0.0028\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0161 - val_loss: 5.4033e-04 - val_mae: 0.0210\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2898e-04 - mae: 0.0111 - val_loss: 8.9663e-04 - val_mae: 0.0268\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0185 - val_loss: 0.0068 - val_mae: 0.0746\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0310\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.0018 - val_mae: 0.0387\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0197 - val_loss: 0.0081 - val_mae: 0.0808\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.6927e-04 - mae: 0.0142 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0154 - val_loss: 4.8716e-06 - val_mae: 0.0015\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0177 - val_loss: 4.1417e-05 - val_mae: 0.0053\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.1426e-04 - mae: 0.0088 - val_loss: 2.3491e-04 - val_mae: 0.0140\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 1.1910e-05 - val_mae: 0.0024\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 3.1840e-06 - val_mae: 0.0015\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0692e-04 - mae: 0.0161 - val_loss: 2.8254e-04 - val_mae: 0.0151\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4839e-04 - mae: 0.0204 - val_loss: 5.4951e-05 - val_mae: 0.0063\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 5.2836e-05 - val_mae: 0.0066\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0269 - val_loss: 0.0037 - val_mae: 0.0551\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 1.9752e-06 - val_mae: 7.1487e-04\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0012 - val_mae: 0.0312\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9318e-04 - mae: 0.0234 - val_loss: 2.7710e-04 - val_mae: 0.0154\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0308\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1031e-04 - mae: 0.0215 - val_loss: 0.0030 - val_mae: 0.0494\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0015 - val_mae: 0.0349\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 1.2451e-06 - val_mae: 3.6214e-04\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6234e-04 - mae: 0.0097 - val_loss: 0.0014 - val_mae: 0.0343\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 0.0125 - val_mae: 0.1003\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0183 - val_loss: 0.0050 - val_mae: 0.0639\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7873e-04 - mae: 0.0139 - val_loss: 2.4786e-05 - val_mae: 0.0043\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 4.2529e-04 - val_mae: 0.0183\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 2.6693e-05 - val_mae: 0.0046\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3698e-04 - mae: 0.0132 - val_loss: 2.4879e-04 - val_mae: 0.0145\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0216 - val_loss: 2.3657e-05 - val_mae: 0.0020\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1944e-04 - mae: 0.0121 - val_loss: 5.3364e-07 - val_mae: 2.5760e-04\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 6.0506e-05 - val_mae: 0.0072\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0012 - val_mae: 0.0314\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6620e-04 - mae: 0.0195 - val_loss: 1.3725e-04 - val_mae: 0.0104\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 1.6192e-04 - val_mae: 0.0117\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 3.8514e-07 - val_mae: 3.6378e-04\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 7.2778e-05 - val_mae: 0.0071\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 5.2720e-05 - val_mae: 0.0065\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 9.8221e-04 - val_mae: 0.0282\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0773e-04 - mae: 0.0162 - val_loss: 1.1400e-06 - val_mae: 8.5836e-04\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 7.3724e-04 - val_mae: 0.0243\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7163e-04 - mae: 0.0196 - val_loss: 5.2141e-07 - val_mae: 6.1346e-04\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9950e-04 - mae: 0.0142 - val_loss: 3.3285e-04 - val_mae: 0.0166\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0028 - val_mae: 0.0474\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.4272e-04 - mae: 0.0110 - val_loss: 4.0026e-04 - val_mae: 0.0182\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 6.6520e-04 - val_mae: 0.0232\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 3.5508e-06 - val_mae: 0.0015\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0024 - val_mae: 0.0445\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1890e-04 - mae: 0.0148 - val_loss: 1.6140e-04 - val_mae: 0.0119\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0156 - val_loss: 8.6070e-07 - val_mae: 7.6223e-04\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 1.4777e-05 - val_mae: 0.0018\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 9.7283e-08 - val_mae: 2.6326e-04\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4270e-04 - mae: 0.0133 - val_loss: 0.0047 - val_mae: 0.0616\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9814e-04 - mae: 0.0218 - val_loss: 0.0027 - val_mae: 0.0459\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6843e-04 - mae: 0.0143 - val_loss: 1.7950e-05 - val_mae: 0.0039\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 0.0029 - val_mae: 0.0484\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0484e-04 - mae: 0.0199 - val_loss: 7.7343e-04 - val_mae: 0.0247\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 2.4168e-06 - val_mae: 9.7150e-04\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1123e-04 - mae: 0.0189 - val_loss: 3.9631e-04 - val_mae: 0.0182\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 0.0013 - val_mae: 0.0324\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 2.6245e-04 - val_mae: 0.0143\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0193 - val_loss: 2.2348e-07 - val_mae: 3.4101e-04\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 7.7054e-07 - val_mae: 5.8193e-04\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4234e-04 - mae: 0.0178 - val_loss: 7.8103e-04 - val_mae: 0.0248\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 1.4257e-05 - val_mae: 0.0036\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0212 - val_loss: 0.0134 - val_mae: 0.1042\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6860e-04 - mae: 0.0129 - val_loss: 6.2231e-06 - val_mae: 0.0022\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0217 - val_loss: 2.8350e-06 - val_mae: 0.0012\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 2.2045e-07 - val_mae: 3.9165e-04\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2431e-04 - mae: 0.0132 - val_loss: 0.0096 - val_mae: 0.0885\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 1.3776e-07 - val_mae: 3.0037e-04\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 5.0642e-06 - val_mae: 0.0017\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8358e-04 - mae: 0.0100 - val_loss: 0.0014 - val_mae: 0.0346\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0174 - val_loss: 6.9631e-07 - val_mae: 7.3360e-04\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0015 - val_mae: 0.0348\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 3.2949e-06 - val_mae: 0.0010\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.7226e-04 - mae: 0.0134 - val_loss: 0.0038 - val_mae: 0.0553\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 1.6277e-06 - val_mae: 0.0011\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 2.7320e-04 - val_mae: 0.0149\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 4.7510e-07 - val_mae: 6.8656e-04\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0161 - val_loss: 5.6817e-04 - val_mae: 0.0214\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.3485e-04 - mae: 0.0099 - val_loss: 1.4409e-04 - val_mae: 0.0112\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.9055e-04 - mae: 0.0154 - val_loss: 5.9391e-05 - val_mae: 0.0070\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0209 - val_loss: 1.8564e-06 - val_mae: 0.0011\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9877e-04 - mae: 0.0159 - val_loss: 1.3757e-04 - val_mae: 0.0108\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 1.0472e-05 - val_mae: 0.0029\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 8.9785e-04 - val_mae: 0.0268\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3079e-04 - mae: 0.0208 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 7.3066e-04 - val_mae: 0.0247\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 4.7092e-06 - val_mae: 6.6263e-04\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 2.3509e-06 - val_mae: 0.0014\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 0.0094 - val_mae: 0.0872\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2210e-04 - mae: 0.0151 - val_loss: 0.0028 - val_mae: 0.0474\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8258e-04 - mae: 0.0182 - val_loss: 0.0029 - val_mae: 0.0484\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0012 - val_mae: 0.0315\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0222 - val_loss: 3.5389e-04 - val_mae: 0.0168\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6695e-04 - mae: 0.0141 - val_loss: 0.0027 - val_mae: 0.0475\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0019 - val_mae: 0.0393\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.9955e-04 - mae: 0.0105 - val_loss: 0.0111 - val_mae: 0.0945\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 8.1939e-07 - val_mae: 8.6200e-04\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0148 - val_loss: 5.1335e-07 - val_mae: 2.6928e-04\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2150e-04 - mae: 0.0088 - val_loss: 0.0095 - val_mae: 0.0879\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0153 - val_loss: 6.2056e-07 - val_mae: 6.5752e-04\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0180 - val_loss: 7.6790e-05 - val_mae: 0.0074\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 2.5831e-06 - val_mae: 8.5457e-04\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.0489e-04 - mae: 0.0123 - val_loss: 0.0017 - val_mae: 0.0373\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0213 - val_loss: 4.8298e-07 - val_mae: 5.7685e-04\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6205e-04 - mae: 0.0131 - val_loss: 0.0011 - val_mae: 0.0298\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9549e-04 - mae: 0.0195 - val_loss: 3.8404e-05 - val_mae: 0.0057\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 2.4577e-04 - val_mae: 0.0142\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0218 - val_loss: 0.0017 - val_mae: 0.0369\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9545e-04 - mae: 0.0192 - val_loss: 8.9446e-06 - val_mae: 0.0025\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 2.4485e-04 - val_mae: 0.0137\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0200 - val_loss: 4.8984e-05 - val_mae: 0.0059\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5863e-04 - mae: 0.0142 - val_loss: 0.0011 - val_mae: 0.0310\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4655e-04 - mae: 0.0163 - val_loss: 0.0027 - val_mae: 0.0469\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 2.4687e-05 - val_mae: 0.0044\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 7.4753e-04 - val_mae: 0.0248\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9637e-04 - mae: 0.0162 - val_loss: 1.6080e-05 - val_mae: 0.0035\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0202 - val_loss: 1.1273e-06 - val_mae: 9.0354e-04\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0134 - val_loss: 6.9878e-05 - val_mae: 0.0077\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.2717e-04 - mae: 0.0087 - val_loss: 3.8185e-04 - val_mae: 0.0176\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0205 - val_loss: 1.0227e-05 - val_mae: 0.0028\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3755e-04 - mae: 0.0163 - val_loss: 1.6149e-04 - val_mae: 0.0118\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3320e-04 - mae: 0.0216 - val_loss: 2.3144e-04 - val_mae: 0.0132\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8666e-04 - mae: 0.0172 - val_loss: 6.2967e-08 - val_mae: 7.7903e-05\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0143 - val_loss: 0.0019 - val_mae: 0.0397\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 7.5096e-05 - val_mae: 0.0084\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.6516e-04 - mae: 0.0154 - val_loss: 5.5632e-04 - val_mae: 0.0215\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 0.0092 - val_mae: 0.0857\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0190 - val_loss: 0.0102 - val_mae: 0.0905\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.4458e-04 - mae: 0.0097 - val_loss: 7.4315e-06 - val_mae: 0.0026\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6656e-04 - mae: 0.0156 - val_loss: 2.9005e-04 - val_mae: 0.0152\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 1.7673e-04 - val_mae: 0.0124\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0203 - val_loss: 6.3777e-06 - val_mae: 0.0020\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 3.9379e-07 - val_mae: 2.2863e-04\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0131 - val_loss: 9.0972e-06 - val_mae: 0.0015\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.9502e-04 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0804\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 4.0333e-04 - val_mae: 0.0182\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 1.6473e-05 - val_mae: 0.0040\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7311e-04 - mae: 0.0200 - val_loss: 2.1557e-05 - val_mae: 0.0020\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 8.4695e-05 - val_mae: 0.0081\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0070 - val_mae: 0.0750\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 8.9453e-06 - val_mae: 0.0026\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.9143e-04 - mae: 0.0145 - val_loss: 7.8724e-06 - val_mae: 0.0013\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0160 - val_loss: 2.3170e-06 - val_mae: 0.0013\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8994e-04 - mae: 0.0142 - val_loss: 0.0035 - val_mae: 0.0537\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.4129e-04 - mae: 0.0146 - val_loss: 2.0345e-04 - val_mae: 0.0134\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 9.3482e-06 - val_mae: 0.0030\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.1090e-04 - mae: 0.0158 - val_loss: 6.8580e-06 - val_mae: 0.0017\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 5.0989e-07 - val_mae: 6.4154e-04\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.2368e-04 - mae: 0.0079 - val_loss: 1.3292e-04 - val_mae: 0.0103\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0176 - val_loss: 6.0890e-06 - val_mae: 8.3336e-04\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0131 - val_loss: 0.0030 - val_mae: 0.0496\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0401e-04 - mae: 0.0124 - val_loss: 0.0080 - val_mae: 0.0803\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 1.4824e-05 - val_mae: 0.0022\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 8.8693e-05 - val_mae: 0.0083\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5036e-04 - mae: 0.0145 - val_loss: 0.0024 - val_mae: 0.0436\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0199 - val_loss: 1.2551e-05 - val_mae: 0.0027\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 5.8382e-07 - val_mae: 7.4165e-04\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.1530e-04 - mae: 0.0152 - val_loss: 5.6697e-05 - val_mae: 0.0062\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0168 - val_loss: 1.0425e-06 - val_mae: 6.4406e-04\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.9096e-04 - mae: 0.0104 - val_loss: 2.0845e-06 - val_mae: 0.0013\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 1.0377e-05 - val_mae: 0.0020\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8467e-04 - mae: 0.0229 - val_loss: 7.4498e-04 - val_mae: 0.0248\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7500e-04 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0291\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 0.0037 - val_mae: 0.0544\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0219 - val_loss: 0.0012 - val_mae: 0.0319\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.1492e-04 - mae: 0.0131 - val_loss: 0.0057 - val_mae: 0.0681\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0183 - val_loss: 0.0033 - val_mae: 0.0514\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6806e-04 - mae: 0.0181 - val_loss: 3.9535e-04 - val_mae: 0.0179\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 5.6033e-05 - val_mae: 0.0067\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0166 - val_loss: 1.3031e-05 - val_mae: 0.0020\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7262e-04 - mae: 0.0170 - val_loss: 8.7063e-05 - val_mae: 0.0082\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 1.8582e-05 - val_mae: 9.0436e-04\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0128 - val_loss: 0.0094 - val_mae: 0.0869\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.5616e-04 - mae: 0.0114 - val_loss: 3.1912e-07 - val_mae: 5.4979e-04\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 4.9737e-05 - val_mae: 0.0061\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0191 - val_loss: 0.0095 - val_mae: 0.0874\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.7493e-04 - mae: 0.0126 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 1.2335e-04 - val_mae: 0.0089\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.5754e-04 - mae: 0.0198 - val_loss: 3.5297e-04 - val_mae: 0.0171\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.8400e-04 - mae: 0.0144 - val_loss: 8.5337e-07 - val_mae: 7.7871e-04\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 5.1112e-07 - val_mae: 6.1718e-04\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2767e-04 - mae: 0.0180 - val_loss: 8.6998e-05 - val_mae: 0.0083\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 2.5636e-07 - val_mae: 2.8128e-04\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 6.1637e-05 - val_mae: 0.0067\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6086e-04 - mae: 0.0167 - val_loss: 0.0048 - val_mae: 0.0632\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0209 - val_loss: 7.3520e-05 - val_mae: 0.0081\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0015 - val_mae: 0.0348\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4319e-04 - mae: 0.0220 - val_loss: 1.0748e-05 - val_mae: 0.0031\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0124e-04 - mae: 0.0215 - val_loss: 8.2966e-04 - val_mae: 0.0260\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 9.8738e-06 - val_mae: 0.0014\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 4.2174e-06 - val_mae: 7.4985e-04\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 6.9354e-04 - val_mae: 0.0239\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8839e-04 - mae: 0.0201 - val_loss: 7.8745e-05 - val_mae: 0.0077\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6190e-04 - mae: 0.0210 - val_loss: 0.0020 - val_mae: 0.0403\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.0047 - val_mae: 0.0613\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0204e-04 - mae: 0.0100 - val_loss: 3.7421e-07 - val_mae: 3.8937e-04\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.5093e-04 - mae: 0.0156 - val_loss: 3.1793e-04 - val_mae: 0.0160\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6054e-04 - mae: 0.0185 - val_loss: 8.5864e-05 - val_mae: 0.0082\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0172 - val_loss: 2.5487e-06 - val_mae: 0.0013\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6814e-04 - mae: 0.0116 - val_loss: 0.0113 - val_mae: 0.0961\n",
            "Epoch 634/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7491e-04 - mae: 0.0124 - val_loss: 0.0010 - val_mae: 0.0290\n",
            "Epoch 635/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.7830e-04 - mae: 0.0162 - val_loss: 0.0041 - val_mae: 0.0568\n",
            "Epoch 636/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0173 - val_loss: 9.2698e-04 - val_mae: 0.0275\n",
            "Epoch 637/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 638/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6636e-04 - mae: 0.0178 - val_loss: 4.5998e-04 - val_mae: 0.0195\n",
            "Epoch 639/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 9.2586e-04 - val_mae: 0.0279\n",
            "Epoch 640/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6075e-04 - mae: 0.0200 - val_loss: 1.0836e-05 - val_mae: 0.0031\n",
            "Epoch 641/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 1.4404e-04 - val_mae: 0.0105\n",
            "Epoch 642/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 7.3741e-06 - val_mae: 0.0012\n",
            "Epoch 643/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0151 - val_loss: 4.1633e-04 - val_mae: 0.0189\n",
            "Epoch 644/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 1.3375e-07 - val_mae: 3.4765e-04\n",
            "Epoch 645/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2546e-04 - mae: 0.0158 - val_loss: 6.5005e-06 - val_mae: 9.2916e-04\n",
            "Epoch 646/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5261e-04 - mae: 0.0192 - val_loss: 2.9062e-05 - val_mae: 0.0051\n",
            "Epoch 647/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5333e-04 - mae: 0.0180 - val_loss: 4.2684e-04 - val_mae: 0.0186\n",
            "Epoch 648/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0169 - val_loss: 2.0444e-05 - val_mae: 0.0036\n",
            "Epoch 649/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 5.4862e-04 - val_mae: 0.0212\n",
            "Epoch 650/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3522e-04 - mae: 0.0207 - val_loss: 1.8227e-04 - val_mae: 0.0121\n",
            "Epoch 651/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0558\n",
            "Epoch 652/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8866e-04 - mae: 0.0139 - val_loss: 5.1421e-05 - val_mae: 0.0062\n",
            "Epoch 653/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 2.1657e-07 - val_mae: 4.5632e-04\n",
            "Epoch 654/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0140 - val_loss: 3.5830e-07 - val_mae: 3.6955e-04\n",
            "Epoch 655/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1604e-04 - mae: 0.0191 - val_loss: 0.0013 - val_mae: 0.0321\n",
            "Epoch 656/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 1.2034e-04 - val_mae: 0.0097\n",
            "Epoch 657/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4797e-04 - mae: 0.0190 - val_loss: 5.8936e-04 - val_mae: 0.0219\n",
            "Epoch 658/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 2.6170e-07 - val_mae: 4.3391e-04\n",
            "Epoch 659/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 6.4403e-05 - val_mae: 0.0067\n",
            "Epoch 660/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 1.6525e-04 - val_mae: 0.0116\n",
            "Epoch 661/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4198e-04 - mae: 0.0177 - val_loss: 3.6945e-05 - val_mae: 0.0058\n",
            "Epoch 662/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 3.8227e-06 - val_mae: 0.0016\n",
            "Epoch 663/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.4676e-04 - mae: 0.0115 - val_loss: 2.5935e-04 - val_mae: 0.0147\n",
            "Epoch 664/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 1.3009e-05 - val_mae: 0.0034\n",
            "Epoch 665/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 1.3806e-05 - val_mae: 0.0033\n",
            "Epoch 666/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5155e-04 - mae: 0.0175 - val_loss: 5.5534e-06 - val_mae: 0.0023\n",
            "Epoch 667/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2330e-04 - mae: 0.0154 - val_loss: 1.2811e-06 - val_mae: 8.6120e-04\n",
            "Epoch 668/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0128 - val_loss: 0.0034 - val_mae: 0.0529\n",
            "Epoch 669/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3630e-04 - mae: 0.0127 - val_loss: 4.0666e-06 - val_mae: 0.0017\n",
            "Epoch 670/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8738e-04 - mae: 0.0234 - val_loss: 1.0272e-04 - val_mae: 0.0098\n",
            "Epoch 671/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0304\n",
            "Epoch 672/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 7.9671e-04 - val_mae: 0.0253\n",
            "Epoch 673/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0197 - val_loss: 7.4673e-06 - val_mae: 6.4107e-04\n",
            "Epoch 674/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2721e-04 - mae: 0.0099 - val_loss: 8.6789e-06 - val_mae: 0.0025\n",
            "Epoch 675/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 4.4989e-07 - val_mae: 6.4034e-04\n",
            "Epoch 676/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5428e-04 - mae: 0.0156 - val_loss: 3.5494e-05 - val_mae: 0.0058\n",
            "Epoch 677/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5285e-04 - mae: 0.0133 - val_loss: 5.7349e-04 - val_mae: 0.0214\n",
            "Epoch 678/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0174 - val_loss: 9.1802e-06 - val_mae: 5.9826e-04\n",
            "Epoch 679/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.7265e-04 - mae: 0.0146 - val_loss: 1.3337e-04 - val_mae: 0.0103\n",
            "Epoch 680/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 3.4198e-04 - val_mae: 0.0164\n",
            "Epoch 681/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 2.3691e-05 - val_mae: 0.0042\n",
            "Epoch 682/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.1863e-04 - mae: 0.0135 - val_loss: 0.0044 - val_mae: 0.0596\n",
            "Epoch 683/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0196 - val_loss: 0.0019 - val_mae: 0.0396\n",
            "Epoch 684/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0208 - val_loss: 0.0014 - val_mae: 0.0338\n",
            "Epoch 685/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2497e-04 - mae: 0.0168 - val_loss: 4.9007e-06 - val_mae: 0.0019\n",
            "Epoch 686/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0186 - val_loss: 8.4030e-04 - val_mae: 0.0262\n",
            "Epoch 687/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0170 - val_loss: 6.0096e-05 - val_mae: 0.0071\n",
            "Epoch 688/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 1.4853e-05 - val_mae: 0.0013\n",
            "Epoch 689/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7239e-04 - mae: 0.0142 - val_loss: 1.9736e-04 - val_mae: 0.0128\n",
            "Epoch 690/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9428e-04 - mae: 0.0189 - val_loss: 0.0088 - val_mae: 0.0854\n",
            "Epoch 691/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0308\n",
            "Epoch 692/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9771e-04 - mae: 0.0187 - val_loss: 7.9248e-06 - val_mae: 0.0022\n",
            "Epoch 693/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8274e-04 - mae: 0.0194 - val_loss: 3.2410e-04 - val_mae: 0.0162\n",
            "Epoch 694/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 1.0791e-06 - val_mae: 7.7727e-04\n",
            "Epoch 695/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4987e-04 - mae: 0.0196 - val_loss: 2.2406e-04 - val_mae: 0.0137\n",
            "Epoch 696/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0170 - val_loss: 1.4261e-06 - val_mae: 6.2892e-04\n",
            "Epoch 697/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6222e-04 - mae: 0.0163 - val_loss: 4.7668e-05 - val_mae: 0.0064\n",
            "Epoch 698/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 1.2952e-04 - val_mae: 0.0105\n",
            "Epoch 699/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.0050 - val_mae: 0.0631\n",
            "Epoch 700/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 5.5081e-06 - val_mae: 0.0021\n",
            "Epoch 701/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 3.4830e-05 - val_mae: 0.0056\n",
            "Epoch 702/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3955e-04 - mae: 0.0103 - val_loss: 3.9289e-05 - val_mae: 0.0058\n",
            "Epoch 703/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0216 - val_loss: 0.0027 - val_mae: 0.0466\n",
            "Epoch 704/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5284e-04 - mae: 0.0218 - val_loss: 0.0028 - val_mae: 0.0471\n",
            "Epoch 705/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8848e-04 - mae: 0.0136 - val_loss: 0.0031 - val_mae: 0.0505\n",
            "Epoch 706/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0198 - val_loss: 0.0017 - val_mae: 0.0376\n",
            "Epoch 707/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.1837e-04 - mae: 0.0188 - val_loss: 0.0044 - val_mae: 0.0603\n",
            "Epoch 708/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 4.4227e-04 - val_mae: 0.0192\n",
            "Epoch 709/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3614e-04 - mae: 0.0161 - val_loss: 4.0107e-06 - val_mae: 0.0019\n",
            "Epoch 710/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7557e-04 - mae: 0.0176 - val_loss: 4.6664e-05 - val_mae: 0.0066\n",
            "Epoch 711/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7140e-04 - mae: 0.0219 - val_loss: 0.0031 - val_mae: 0.0502\n",
            "Epoch 712/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 8.2516e-04 - val_mae: 0.0259\n",
            "Epoch 713/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 8.5938e-04 - val_mae: 0.0266\n",
            "Epoch 714/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4412e-04 - mae: 0.0202 - val_loss: 1.4776e-05 - val_mae: 0.0037\n",
            "Epoch 715/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7.9837e-04 - mae: 0.0103 - val_loss: 0.0036 - val_mae: 0.0544\n",
            "Epoch 716/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 9.0226e-06 - val_mae: 0.0013\n",
            "Epoch 717/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0159 - val_loss: 4.3534e-06 - val_mae: 0.0012\n",
            "Epoch 718/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.9798e-04 - mae: 0.0066 - val_loss: 3.8984e-05 - val_mae: 0.0056\n",
            "Epoch 719/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 720/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 6.9497e-07 - val_mae: 7.6340e-04\n",
            "Epoch 721/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0185 - val_loss: 1.8295e-06 - val_mae: 0.0012\n",
            "Epoch 722/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6840e-04 - mae: 0.0171 - val_loss: 4.4261e-04 - val_mae: 0.0187\n",
            "Epoch 723/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 1.3799e-07 - val_mae: 2.9083e-04\n",
            "Epoch 724/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 4.3797e-04 - val_mae: 0.0188\n",
            "Epoch 725/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8732e-04 - mae: 0.0182 - val_loss: 7.7385e-07 - val_mae: 2.7423e-04\n",
            "Epoch 726/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2263e-04 - mae: 0.0199 - val_loss: 1.0528e-05 - val_mae: 9.1937e-04\n",
            "Epoch 727/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9685e-04 - mae: 0.0148 - val_loss: 1.9761e-05 - val_mae: 0.0042\n",
            "Epoch 728/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.6180e-04 - mae: 0.0183 - val_loss: 3.4587e-04 - val_mae: 0.0168\n",
            "Epoch 729/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 3.0226e-08 - val_mae: 1.4162e-04\n",
            "Epoch 730/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4998e-04 - mae: 0.0173 - val_loss: 3.4953e-06 - val_mae: 0.0015\n",
            "Epoch 731/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4124e-04 - mae: 0.0191 - val_loss: 4.8737e-04 - val_mae: 0.0201\n",
            "Epoch 732/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 7.6330e-06 - val_mae: 0.0020\n",
            "Epoch 733/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 2.1763e-06 - val_mae: 0.0014\n",
            "Epoch 734/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0691e-04 - mae: 0.0172 - val_loss: 3.3162e-04 - val_mae: 0.0159\n",
            "Epoch 735/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9072e-04 - mae: 0.0145 - val_loss: 3.2622e-06 - val_mae: 0.0018\n",
            "Epoch 736/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 1.2505e-06 - val_mae: 9.2328e-04\n",
            "Epoch 737/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.7079e-04 - mae: 0.0185 - val_loss: 0.0026 - val_mae: 0.0455\n",
            "Epoch 738/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 3.6120e-04 - val_mae: 0.0176\n",
            "Epoch 739/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 4.8762e-05 - val_mae: 0.0059\n",
            "Epoch 740/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7109e-04 - mae: 0.0151 - val_loss: 1.1741e-05 - val_mae: 0.0025\n",
            "Epoch 741/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 5.6656e-06 - val_mae: 0.0022\n",
            "Epoch 742/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9280e-04 - mae: 0.0113 - val_loss: 0.0024 - val_mae: 0.0438\n",
            "Epoch 743/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 4.1880e-06 - val_mae: 8.9487e-04\n",
            "Epoch 744/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5000e-04 - mae: 0.0184 - val_loss: 1.6416e-04 - val_mae: 0.0114\n",
            "Epoch 745/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0159e-04 - mae: 0.0184 - val_loss: 7.2745e-06 - val_mae: 0.0022\n",
            "Epoch 746/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0178 - val_loss: 4.7818e-07 - val_mae: 3.6131e-04\n",
            "Epoch 747/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1879e-04 - mae: 0.0146 - val_loss: 6.8232e-06 - val_mae: 0.0024\n",
            "Epoch 748/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7202e-04 - mae: 0.0213 - val_loss: 4.3042e-04 - val_mae: 0.0192\n",
            "Epoch 749/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7843e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0290\n",
            "Epoch 750/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 4.3341e-06 - val_mae: 0.0020\n",
            "Epoch 751/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0010e-04 - mae: 0.0157 - val_loss: 0.0051 - val_mae: 0.0644\n",
            "Epoch 752/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0165 - val_loss: 5.0282e-06 - val_mae: 6.9568e-04\n",
            "Epoch 753/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 0.0092 - val_mae: 0.0861\n",
            "Epoch 754/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3302e-04 - mae: 0.0182 - val_loss: 0.0067 - val_mae: 0.0739\n",
            "Epoch 755/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7.8953e-04 - mae: 0.0118 - val_loss: 0.0011 - val_mae: 0.0303\n",
            "Epoch 756/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 7.0100e-06 - val_mae: 0.0017\n",
            "Epoch 757/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 2.0414e-04 - val_mae: 0.0129\n",
            "Epoch 758/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3859e-04 - mae: 0.0148 - val_loss: 5.0901e-05 - val_mae: 0.0061\n",
            "Epoch 759/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6140e-04 - mae: 0.0178 - val_loss: 3.7419e-05 - val_mae: 0.0042\n",
            "Epoch 760/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 9.2188e-05 - val_mae: 0.0085\n",
            "Epoch 761/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 4.7886e-04 - val_mae: 0.0194\n",
            "Epoch 762/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0546e-04 - mae: 0.0185 - val_loss: 4.9099e-06 - val_mae: 0.0018\n",
            "Epoch 763/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.8154e-04 - mae: 0.0095 - val_loss: 0.0065 - val_mae: 0.0727\n",
            "Epoch 764/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 9.2973e-04 - val_mae: 0.0277\n",
            "Epoch 765/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 3.5507e-05 - val_mae: 0.0059\n",
            "Epoch 766/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 1.3589e-06 - val_mae: 0.0010\n",
            "Epoch 767/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5104e-04 - mae: 0.0193 - val_loss: 7.2577e-06 - val_mae: 0.0018\n",
            "Epoch 768/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.4226e-04 - mae: 0.0141 - val_loss: 6.6894e-05 - val_mae: 0.0070\n",
            "Epoch 769/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0186 - val_loss: 0.0023 - val_mae: 0.0436\n",
            "Epoch 770/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6557e-04 - mae: 0.0159 - val_loss: 3.8577e-06 - val_mae: 0.0016\n",
            "Epoch 771/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6728e-04 - mae: 0.0166 - val_loss: 9.3869e-06 - val_mae: 0.0025\n",
            "Epoch 772/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 4.3996e-05 - val_mae: 0.0062\n",
            "Epoch 773/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 1.4050e-06 - val_mae: 8.0032e-04\n",
            "Epoch 774/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.1038e-04 - mae: 0.0155 - val_loss: 0.0010 - val_mae: 0.0288\n",
            "Epoch 775/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0013 - val_mae: 0.0324\n",
            "Epoch 776/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3732e-04 - mae: 0.0198 - val_loss: 4.7230e-05 - val_mae: 0.0061\n",
            "Epoch 777/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0183 - val_loss: 3.2235e-07 - val_mae: 5.1787e-04\n",
            "Epoch 778/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5175e-04 - mae: 0.0083 - val_loss: 4.5622e-07 - val_mae: 3.1303e-04\n",
            "Epoch 779/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 1.3497e-06 - val_mae: 9.6609e-04\n",
            "Epoch 780/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.5558e-04 - mae: 0.0075 - val_loss: 7.9494e-05 - val_mae: 0.0080\n",
            "Epoch 781/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 4.1652e-04 - val_mae: 0.0183\n",
            "Epoch 782/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 0.0063 - val_mae: 0.0710\n",
            "Epoch 783/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.8490e-04 - mae: 0.0124 - val_loss: 2.1669e-06 - val_mae: 6.3418e-04\n",
            "Epoch 784/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7.4448e-04 - mae: 0.0125 - val_loss: 1.4114e-04 - val_mae: 0.0108\n",
            "Epoch 785/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9739e-04 - mae: 0.0199 - val_loss: 1.1592e-05 - val_mae: 0.0032\n",
            "Epoch 786/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 3.7252e-07 - val_mae: 5.7953e-04\n",
            "Epoch 787/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6971e-04 - mae: 0.0179 - val_loss: 0.0020 - val_mae: 0.0408\n",
            "Epoch 788/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3022e-04 - mae: 0.0153 - val_loss: 1.1582e-05 - val_mae: 0.0031\n",
            "Epoch 789/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0191 - val_loss: 7.4681e-07 - val_mae: 7.0042e-04\n",
            "Epoch 790/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 1.0630e-04 - val_mae: 0.0096\n",
            "Epoch 791/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.6950e-04 - mae: 0.0167 - val_loss: 7.0338e-06 - val_mae: 0.0015\n",
            "Epoch 792/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0145 - val_loss: 3.6871e-04 - val_mae: 0.0169\n",
            "Epoch 793/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0266e-04 - mae: 0.0135 - val_loss: 2.7579e-05 - val_mae: 0.0012\n",
            "Epoch 794/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.3491e-04 - mae: 0.0117 - val_loss: 8.9650e-04 - val_mae: 0.0269\n",
            "Epoch 795/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 3.5604e-06 - val_mae: 0.0016\n",
            "Epoch 796/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2689e-04 - mae: 0.0166 - val_loss: 3.6500e-06 - val_mae: 0.0016\n",
            "Epoch 797/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 3.6467e-04 - val_mae: 0.0173\n",
            "Epoch 798/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7498e-04 - mae: 0.0124 - val_loss: 1.1613e-04 - val_mae: 0.0102\n",
            "Epoch 799/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0609e-04 - mae: 0.0219 - val_loss: 0.0074 - val_mae: 0.0771\n",
            "Epoch 800/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0158 - val_loss: 2.7013e-06 - val_mae: 0.0015\n",
            "Epoch 801/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1990e-04 - mae: 0.0179 - val_loss: 2.7866e-06 - val_mae: 0.0011\n",
            "Epoch 802/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0026 - val_mae: 0.0464\n",
            "Epoch 803/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3869e-04 - mae: 0.0156 - val_loss: 8.6925e-05 - val_mae: 0.0084\n",
            "Epoch 804/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 3.7514e-04 - val_mae: 0.0167\n",
            "Epoch 805/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 1.0561e-06 - val_mae: 8.7322e-04\n",
            "Epoch 806/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.0714e-04 - mae: 0.0103 - val_loss: 0.0060 - val_mae: 0.0697\n",
            "Epoch 807/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0142 - val_loss: 2.8837e-04 - val_mae: 0.0159\n",
            "Epoch 808/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7679e-04 - mae: 0.0192 - val_loss: 8.9885e-05 - val_mae: 0.0087\n",
            "Epoch 809/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0014 - val_mae: 0.0334\n",
            "Epoch 810/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4168e-04 - mae: 0.0111 - val_loss: 0.0101 - val_mae: 0.0907\n",
            "Epoch 811/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0152 - val_loss: 0.0030 - val_mae: 0.0492\n",
            "Epoch 812/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2624e-04 - mae: 0.0172 - val_loss: 1.0814e-07 - val_mae: 2.0754e-04\n",
            "Epoch 813/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5756e-04 - mae: 0.0090 - val_loss: 1.0043e-04 - val_mae: 0.0090\n",
            "Epoch 814/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 7.1642e-05 - val_mae: 0.0077\n",
            "Epoch 815/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5414e-04 - mae: 0.0178 - val_loss: 1.1208e-04 - val_mae: 0.0088\n",
            "Epoch 816/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 1.2718e-06 - val_mae: 7.9527e-04\n",
            "Epoch 817/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7267e-04 - mae: 0.0195 - val_loss: 0.0018 - val_mae: 0.0387\n",
            "Epoch 818/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.2254e-04 - mae: 0.0226 - val_loss: 8.6468e-04 - val_mae: 0.0256\n",
            "Epoch 819/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1357e-04 - mae: 0.0215 - val_loss: 4.8021e-04 - val_mae: 0.0201\n",
            "Epoch 820/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0202 - val_loss: 4.3236e-06 - val_mae: 5.2651e-04\n",
            "Epoch 821/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.4946e-04 - mae: 0.0077 - val_loss: 3.8686e-07 - val_mae: 4.2986e-04\n",
            "Epoch 822/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0152 - val_loss: 5.3135e-06 - val_mae: 0.0018\n",
            "Epoch 823/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 1.3608e-06 - val_mae: 9.7440e-04\n",
            "Epoch 824/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.7861e-04 - mae: 0.0135 - val_loss: 0.0019 - val_mae: 0.0395\n",
            "Epoch 825/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0186 - val_loss: 0.0056 - val_mae: 0.0678\n",
            "Epoch 826/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 1.0186e-04 - val_mae: 0.0086\n",
            "Epoch 827/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8941e-04 - mae: 0.0133 - val_loss: 4.0087e-04 - val_mae: 0.0179\n",
            "Epoch 828/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4401e-04 - mae: 0.0198 - val_loss: 7.0238e-04 - val_mae: 0.0246\n",
            "Epoch 829/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0020 - val_mae: 0.0403\n",
            "Epoch 830/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3689e-04 - mae: 0.0201 - val_loss: 4.6829e-07 - val_mae: 5.7340e-04\n",
            "Epoch 831/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 3.2331e-04 - val_mae: 0.0164\n",
            "Epoch 832/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.3486e-04 - mae: 0.0171 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 833/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8240e-04 - mae: 0.0138 - val_loss: 1.4087e-04 - val_mae: 0.0104\n",
            "Epoch 834/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 1.4882e-06 - val_mae: 9.4286e-04\n",
            "Epoch 835/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 1.7860e-05 - val_mae: 0.0023\n",
            "Epoch 836/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.8263e-04 - mae: 0.0174 - val_loss: 3.3074e-06 - val_mae: 5.3984e-04\n",
            "Epoch 837/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1044e-04 - mae: 0.0154 - val_loss: 4.6949e-04 - val_mae: 0.0198\n",
            "Epoch 838/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0499e-04 - mae: 0.0226 - val_loss: 3.5614e-04 - val_mae: 0.0172\n",
            "Epoch 839/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 6.1987e-05 - val_mae: 0.0074\n",
            "Epoch 840/1000\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.1400e-04 - mae: 0.0136 - val_loss: 5.7121e-06 - val_mae: 0.0015\n",
            "Epoch 841/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9629e-04 - mae: 0.0223 - val_loss: 7.4301e-05 - val_mae: 0.0076\n",
            "Epoch 842/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 3.1190e-06 - val_mae: 0.0012\n",
            "Epoch 843/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.0053e-04 - mae: 0.0114 - val_loss: 1.9126e-04 - val_mae: 0.0123\n",
            "Epoch 844/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0051 - val_mae: 0.0640\n",
            "Epoch 845/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0299\n",
            "Epoch 846/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3074e-04 - mae: 0.0165 - val_loss: 4.5822e-04 - val_mae: 0.0198\n",
            "Epoch 847/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8929e-04 - mae: 0.0199 - val_loss: 1.0074e-06 - val_mae: 9.4912e-04\n",
            "Epoch 848/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1606e-04 - mae: 0.0210 - val_loss: 4.6427e-04 - val_mae: 0.0196\n",
            "Epoch 849/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 2.8745e-04 - val_mae: 0.0147\n",
            "Epoch 850/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.3933e-04 - mae: 0.0149 - val_loss: 0.0026 - val_mae: 0.0456\n",
            "Epoch 851/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 5.6226e-06 - val_mae: 0.0010\n",
            "Epoch 852/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 853/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8406e-04 - mae: 0.0151 - val_loss: 1.2082e-05 - val_mae: 0.0034\n",
            "Epoch 854/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 1.7336e-06 - val_mae: 0.0010\n",
            "Epoch 855/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.8222e-04 - mae: 0.0144 - val_loss: 0.0055 - val_mae: 0.0665\n",
            "Epoch 856/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 0.0014 - val_mae: 0.0343\n",
            "Epoch 857/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 2.6398e-07 - val_mae: 1.3790e-04\n",
            "Epoch 858/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5631e-04 - mae: 0.0183 - val_loss: 8.1600e-05 - val_mae: 0.0085\n",
            "Epoch 859/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2907e-04 - mae: 0.0152 - val_loss: 5.8075e-06 - val_mae: 0.0019\n",
            "Epoch 860/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0164 - val_loss: 7.9776e-05 - val_mae: 0.0081\n",
            "Epoch 861/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9514e-04 - mae: 0.0191 - val_loss: 2.4186e-04 - val_mae: 0.0142\n",
            "Epoch 862/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.7173e-04 - mae: 0.0090 - val_loss: 0.0028 - val_mae: 0.0469\n",
            "Epoch 863/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0199 - val_loss: 6.0120e-06 - val_mae: 0.0020\n",
            "Epoch 864/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 1.1107e-05 - val_mae: 0.0023\n",
            "Epoch 865/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4558e-04 - mae: 0.0186 - val_loss: 4.4700e-07 - val_mae: 4.0592e-04\n",
            "Epoch 866/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4044e-04 - mae: 0.0189 - val_loss: 3.6971e-04 - val_mae: 0.0172\n",
            "Epoch 867/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 1.9845e-07 - val_mae: 3.5368e-04\n",
            "Epoch 868/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.4985e-04 - mae: 0.0153 - val_loss: 0.0011 - val_mae: 0.0295\n",
            "Epoch 869/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0187 - val_loss: 0.0040 - val_mae: 0.0567\n",
            "Epoch 870/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6262e-04 - mae: 0.0235 - val_loss: 3.2144e-05 - val_mae: 0.0048\n",
            "Epoch 871/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2332e-04 - mae: 0.0191 - val_loss: 2.6338e-04 - val_mae: 0.0150\n",
            "Epoch 872/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 2.6985e-06 - val_mae: 5.4342e-04\n",
            "Epoch 873/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.5834e-04 - mae: 0.0144 - val_loss: 0.0044 - val_mae: 0.0597\n",
            "Epoch 874/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1098e-04 - mae: 0.0145 - val_loss: 2.9818e-05 - val_mae: 0.0050\n",
            "Epoch 875/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 8.5385e-06 - val_mae: 0.0022\n",
            "Epoch 876/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.3780e-04 - mae: 0.0083 - val_loss: 3.7671e-05 - val_mae: 0.0053\n",
            "Epoch 877/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7008e-04 - mae: 0.0195 - val_loss: 0.0018 - val_mae: 0.0387\n",
            "Epoch 878/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 2.5920e-05 - val_mae: 0.0042\n",
            "Epoch 879/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0014 - val_mae: 0.0331\n",
            "Epoch 880/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7757e-04 - mae: 0.0192 - val_loss: 7.8971e-04 - val_mae: 0.0255\n",
            "Epoch 881/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.9681e-04 - mae: 0.0157 - val_loss: 1.5376e-06 - val_mae: 8.3621e-04\n",
            "Epoch 882/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 883/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1160e-04 - mae: 0.0174 - val_loss: 1.1906e-04 - val_mae: 0.0102\n",
            "Epoch 884/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0012 - val_mae: 0.0315\n",
            "Epoch 885/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 1.7647e-06 - val_mae: 0.0010\n",
            "Epoch 886/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.3151e-04 - mae: 0.0124 - val_loss: 9.4536e-04 - val_mae: 0.0284\n",
            "Epoch 887/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0298\n",
            "Epoch 888/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5310e-04 - mae: 0.0124 - val_loss: 0.0115 - val_mae: 0.0961\n",
            "Epoch 889/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0156 - val_loss: 0.0031 - val_mae: 0.0501\n",
            "Epoch 890/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6830e-04 - mae: 0.0137 - val_loss: 0.0035 - val_mae: 0.0529\n",
            "Epoch 891/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4923e-04 - mae: 0.0147 - val_loss: 7.3686e-04 - val_mae: 0.0250\n",
            "Epoch 892/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 2.5549e-04 - val_mae: 0.0140\n",
            "Epoch 893/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8643e-04 - mae: 0.0239 - val_loss: 1.6888e-05 - val_mae: 0.0037\n",
            "Epoch 894/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3016e-04 - mae: 0.0194 - val_loss: 1.3560e-05 - val_mae: 0.0016\n",
            "Epoch 895/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 1.9028e-05 - val_mae: 0.0037\n",
            "Epoch 896/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2391e-04 - mae: 0.0196 - val_loss: 4.3125e-04 - val_mae: 0.0186\n",
            "Epoch 897/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 2.8723e-06 - val_mae: 0.0012\n",
            "Epoch 898/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1718e-04 - mae: 0.0182 - val_loss: 0.0056 - val_mae: 0.0671\n",
            "Epoch 899/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.6675e-04 - mae: 0.0140 - val_loss: 0.0011 - val_mae: 0.0295\n",
            "Epoch 900/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 2.5729e-05 - val_mae: 0.0024\n",
            "Epoch 901/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0180 - val_loss: 3.0935e-05 - val_mae: 0.0047\n",
            "Epoch 902/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.2896e-04 - mae: 0.0107 - val_loss: 0.0052 - val_mae: 0.0647\n",
            "Epoch 903/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9321e-04 - mae: 0.0185 - val_loss: 2.1448e-04 - val_mae: 0.0132\n",
            "Epoch 904/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.4290e-04 - mae: 0.0184 - val_loss: 6.2583e-05 - val_mae: 0.0072\n",
            "Epoch 905/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.4911e-04 - mae: 0.0221 - val_loss: 1.6005e-06 - val_mae: 0.0011\n",
            "Epoch 906/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7014e-04 - mae: 0.0215 - val_loss: 0.0012 - val_mae: 0.0300\n",
            "Epoch 907/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0235 - val_loss: 1.9012e-04 - val_mae: 0.0127\n",
            "Epoch 908/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.8587e-04 - mae: 0.0216 - val_loss: 0.0011 - val_mae: 0.0304\n",
            "Epoch 909/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2465e-04 - mae: 0.0201 - val_loss: 7.7964e-04 - val_mae: 0.0253\n",
            "Epoch 910/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 3.4191e-08 - val_mae: 5.7790e-05\n",
            "Epoch 911/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.6936e-04 - mae: 0.0086 - val_loss: 0.0013 - val_mae: 0.0328\n",
            "Epoch 912/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0175 - val_loss: 1.3025e-05 - val_mae: 8.1305e-04\n",
            "Epoch 913/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.4995e-04 - mae: 0.0096 - val_loss: 0.0011 - val_mae: 0.0306\n",
            "Epoch 914/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0117 - val_mae: 0.0972\n",
            "Epoch 915/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9525e-04 - mae: 0.0136 - val_loss: 6.7801e-07 - val_mae: 6.6100e-04\n",
            "Epoch 916/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0293\n",
            "Epoch 917/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0176 - val_loss: 2.4036e-05 - val_mae: 0.0035\n",
            "Epoch 918/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.0767e-04 - mae: 0.0127 - val_loss: 0.0010 - val_mae: 0.0285\n",
            "Epoch 919/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0643e-04 - mae: 0.0211 - val_loss: 2.6965e-04 - val_mae: 0.0143\n",
            "Epoch 920/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 3.0289e-05 - val_mae: 0.0022\n",
            "Epoch 921/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.0609e-04 - mae: 0.0149 - val_loss: 8.3323e-05 - val_mae: 0.0077\n",
            "Epoch 922/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7.4298e-04 - mae: 0.0147 - val_loss: 0.0069 - val_mae: 0.0749\n",
            "Epoch 923/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2045e-04 - mae: 0.0185 - val_loss: 1.8789e-06 - val_mae: 8.4913e-04\n",
            "Epoch 924/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0150 - val_loss: 0.0013 - val_mae: 0.0325\n",
            "Epoch 925/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 1.1032e-05 - val_mae: 0.0016\n",
            "Epoch 926/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8263e-04 - mae: 0.0201 - val_loss: 0.0011 - val_mae: 0.0297\n",
            "Epoch 927/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 5.8830e-04 - mae: 0.0099 - val_loss: 5.2311e-05 - val_mae: 0.0064\n",
            "Epoch 928/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0192 - val_loss: 7.4332e-05 - val_mae: 0.0079\n",
            "Epoch 929/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5622e-04 - mae: 0.0194 - val_loss: 5.5217e-06 - val_mae: 0.0015\n",
            "Epoch 930/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.7476e-04 - mae: 0.0141 - val_loss: 4.5301e-06 - val_mae: 0.0013\n",
            "Epoch 931/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.0108e-04 - mae: 0.0151 - val_loss: 3.3715e-05 - val_mae: 0.0054\n",
            "Epoch 932/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1829e-04 - mae: 0.0143 - val_loss: 3.1215e-07 - val_mae: 5.4239e-04\n",
            "Epoch 933/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0122 - val_loss: 0.0028 - val_mae: 0.0473\n",
            "Epoch 934/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.5586e-04 - mae: 0.0181 - val_loss: 7.4406e-05 - val_mae: 0.0080\n",
            "Epoch 935/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 2.6630e-05 - val_mae: 0.0045\n",
            "Epoch 936/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.4975e-04 - mae: 0.0097 - val_loss: 3.2044e-07 - val_mae: 5.2158e-04\n",
            "Epoch 937/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 4.2282e-05 - val_mae: 0.0049\n",
            "Epoch 938/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.1784e-04 - mae: 0.0200 - val_loss: 4.7032e-06 - val_mae: 0.0019\n",
            "Epoch 939/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.9356e-04 - mae: 0.0160 - val_loss: 2.8289e-06 - val_mae: 0.0013\n",
            "Epoch 940/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.3415e-04 - mae: 0.0173 - val_loss: 9.6226e-05 - val_mae: 0.0087\n",
            "Epoch 941/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2650e-04 - mae: 0.0177 - val_loss: 0.0015 - val_mae: 0.0349\n",
            "Epoch 942/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 4.7796e-05 - val_mae: 0.0061\n",
            "Epoch 943/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5470e-04 - mae: 0.0159 - val_loss: 1.1029e-04 - val_mae: 0.0091\n",
            "Epoch 944/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3324e-04 - mae: 0.0159 - val_loss: 0.0020 - val_mae: 0.0399\n",
            "Epoch 945/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0175 - val_loss: 0.0028 - val_mae: 0.0472\n",
            "Epoch 946/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.8417e-04 - mae: 0.0107 - val_loss: 0.0031 - val_mae: 0.0501\n",
            "Epoch 947/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 0.0021 - val_mae: 0.0413\n",
            "Epoch 948/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8917e-04 - mae: 0.0182 - val_loss: 5.6659e-04 - val_mae: 0.0211\n",
            "Epoch 949/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.7213e-04 - mae: 0.0123 - val_loss: 0.0013 - val_mae: 0.0328\n",
            "Epoch 950/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0155 - val_loss: 0.0117 - val_mae: 0.0971\n",
            "Epoch 951/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1807e-04 - mae: 0.0151 - val_loss: 9.0409e-06 - val_mae: 0.0025\n",
            "Epoch 952/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9045e-04 - mae: 0.0192 - val_loss: 2.1342e-06 - val_mae: 0.0012\n",
            "Epoch 953/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1680e-04 - mae: 0.0221 - val_loss: 9.2165e-04 - val_mae: 0.0276\n",
            "Epoch 954/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1360e-04 - mae: 0.0144 - val_loss: 9.1192e-06 - val_mae: 0.0026\n",
            "Epoch 955/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 1.0856e-06 - val_mae: 5.5364e-04\n",
            "Epoch 956/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9534e-04 - mae: 0.0196 - val_loss: 1.6820e-04 - val_mae: 0.0112\n",
            "Epoch 957/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 8.4798e-07 - val_mae: 8.5655e-04\n",
            "Epoch 958/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2720e-04 - mae: 0.0179 - val_loss: 0.0031 - val_mae: 0.0496\n",
            "Epoch 959/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0215 - val_loss: 3.0238e-05 - val_mae: 0.0047\n",
            "Epoch 960/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.0377e-04 - mae: 0.0153 - val_loss: 0.0019 - val_mae: 0.0387\n",
            "Epoch 961/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0226 - val_loss: 1.1816e-05 - val_mae: 0.0029\n",
            "Epoch 962/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9256e-04 - mae: 0.0154 - val_loss: 9.2048e-05 - val_mae: 0.0088\n",
            "Epoch 963/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.5519e-04 - mae: 0.0130 - val_loss: 0.0061 - val_mae: 0.0699\n",
            "Epoch 964/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1900e-04 - mae: 0.0154 - val_loss: 0.0031 - val_mae: 0.0498\n",
            "Epoch 965/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 1.8855e-04 - val_mae: 0.0129\n",
            "Epoch 966/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5271e-04 - mae: 0.0208 - val_loss: 4.0282e-05 - val_mae: 0.0054\n",
            "Epoch 967/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2806e-04 - mae: 0.0162 - val_loss: 1.9315e-07 - val_mae: 3.5494e-04\n",
            "Epoch 968/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0128 - val_loss: 3.0893e-07 - val_mae: 3.6306e-04\n",
            "Epoch 969/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.1150e-04 - mae: 0.0144 - val_loss: 3.6934e-06 - val_mae: 0.0019\n",
            "Epoch 970/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2800e-04 - mae: 0.0150 - val_loss: 3.9140e-05 - val_mae: 0.0057\n",
            "Epoch 971/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 4.8925e-04 - val_mae: 0.0199\n",
            "Epoch 972/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.9220e-04 - mae: 0.0167 - val_loss: 1.2816e-04 - val_mae: 0.0104\n",
            "Epoch 973/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0189 - val_loss: 3.8283e-04 - val_mae: 0.0184\n",
            "Epoch 974/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 2.3172e-06 - val_mae: 0.0015\n",
            "Epoch 975/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.2577e-04 - mae: 0.0182 - val_loss: 2.6207e-04 - val_mae: 0.0140\n",
            "Epoch 976/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6950e-04 - mae: 0.0237 - val_loss: 0.0010 - val_mae: 0.0290\n",
            "Epoch 977/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.1068e-04 - mae: 0.0190 - val_loss: 4.4539e-06 - val_mae: 0.0010\n",
            "Epoch 978/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0156 - val_loss: 3.4925e-04 - val_mae: 0.0167\n",
            "Epoch 979/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8288e-04 - mae: 0.0221 - val_loss: 6.7501e-08 - val_mae: 1.2030e-04\n",
            "Epoch 980/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7019e-04 - mae: 0.0180 - val_loss: 2.3100e-06 - val_mae: 0.0015\n",
            "Epoch 981/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1759e-04 - mae: 0.0158 - val_loss: 7.3481e-06 - val_mae: 0.0024\n",
            "Epoch 982/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 1.7985e-05 - val_mae: 0.0011\n",
            "Epoch 983/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.5604e-04 - mae: 0.0090 - val_loss: 0.0011 - val_mae: 0.0302\n",
            "Epoch 984/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0159 - val_loss: 9.2310e-07 - val_mae: 2.1596e-04\n",
            "Epoch 985/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0153 - val_loss: 1.3411e-05 - val_mae: 0.0031\n",
            "Epoch 986/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2289e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0298\n",
            "Epoch 987/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 6.8326e-05 - val_mae: 0.0076\n",
            "Epoch 988/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3720e-04 - mae: 0.0150 - val_loss: 3.4500e-05 - val_mae: 0.0050\n",
            "Epoch 989/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.6257e-04 - mae: 0.0112 - val_loss: 0.0047 - val_mae: 0.0618\n",
            "Epoch 990/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.1459e-04 - mae: 0.0110 - val_loss: 0.0042 - val_mae: 0.0583\n",
            "Epoch 991/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.8444e-04 - mae: 0.0192 - val_loss: 2.6429e-06 - val_mae: 0.0013\n",
            "Epoch 992/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0183 - val_loss: 1.4419e-06 - val_mae: 8.7997e-04\n",
            "Epoch 993/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8.9548e-04 - mae: 0.0173 - val_loss: 2.3143e-05 - val_mae: 0.0045\n",
            "Epoch 994/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 5.4134e-07 - val_mae: 5.9510e-04\n",
            "Epoch 995/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.6232e-04 - mae: 0.0078 - val_loss: 5.6594e-05 - val_mae: 0.0068\n",
            "Epoch 996/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 9.2319e-04 - mae: 0.0187 - val_loss: 3.9229e-05 - val_mae: 0.0055\n",
            "Epoch 997/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0176 - val_loss: 1.5115e-05 - val_mae: 0.0012\n",
            "Epoch 998/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.1636e-04 - mae: 0.0132 - val_loss: 0.0028 - val_mae: 0.0476\n",
            "Epoch 999/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.7824e-04 - mae: 0.0218 - val_loss: 9.7823e-05 - val_mae: 0.0082\n",
            "Epoch 1000/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9645e-04 - mae: 0.0174 - val_loss: 0.0018 - val_mae: 0.0387\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86FEo80XhW",
        "colab_type": "text"
      },
      "source": [
        "## Convert the Tensorflow Model to Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egny1KLL0Wm0",
        "colab_type": "code",
        "outputId": "7b085556-5865-40fa-9395-494573869147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFc5JmXo41H1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQ7W8d-7PXK",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGzRSdA478s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model to make predictions from our test data\n",
        "\n",
        "############################################################\n",
        "#@markdown How to use the model to predict the result with the test data (`x_test`) and save the result in a variable `predictions`?\n",
        "script = \"prediction=model(x_test)\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH5sWiu7RhT",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8_k-vvwop0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "5ba01468-1989-4eab-8fe3-8b71f2f7bf51"
      },
      "source": [
        "# Use the Tensorflow lite model to make interfences from our test data\n",
        "#@markdown Please choose and fill in correct code statements from one of the following:\n",
        "#@markdown 1. interpreter.invoke() \n",
        "#@markdown 2. interpreter_input().fill(x_test[i])\n",
        "#@markdown 3. interpreter = tf.lite.Interpreter('model.tflite')\n",
        "#@markdown 4. interpreter_predictions[i] = interpreter_output()[0]\n",
        "#@markdown 5. interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "#@markdown 6. interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
        "\n",
        "############################################################\n",
        "# Instantiate an interpreter for the TFLite model\n",
        "#@markdown Which is the statement to instantiate an interpreter with a TFLite Model named `model.tflite`?\n",
        "script_1 = \"interpreter = tf.lite.Interpreter('model.tflite')\" #@param {type:\"string\"}\n",
        "exec(script_1)\n",
        "############################################################\n",
        "\n",
        "# Allocate memory for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "############################################################\n",
        "# Get the input tensors so we can feed in values \n",
        "#@markdown Which is the statement to get input sensors?\n",
        "script_2 = \"interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_2)\n",
        "############################################################\n",
        "\n",
        "############################################################\n",
        "# Get the output tensors so we can get the results\n",
        "#@markdown Which is the statement to get output sensors?\n",
        "script_3 = \"interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_3)\n",
        "############################################################\n",
        "\n",
        "# Create arrays to store the results\n",
        "interpreter_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to fill the input of the interpreter with `x_test[i]`?\n",
        "  script_4 = \"interpreter_input().fill(x_test[i])\" #@param {type:\"string\"}\n",
        "  exec(script_4)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to invoke the interpreter?\n",
        "  script_5 = \"interpreter.invoke() \" #@param {type:\"string\"}\n",
        "  exec(script_5)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to get the output from the interpreter and save the output in `interpreter_predictions[i]`?\n",
        "  script_6 = \"interpreter_predictions[i] = interpreter_output()[0]\"#@param {type:\"string\"}\n",
        "  exec(script_6)\n",
        "  ############################################################\n",
        "\n",
        "\n",
        "# Make the shape of the y_test be the same as the predictions\n",
        "y_test = np.reshape(y_test, predictions.shape)\n",
        "# Make the shape of the interpreter_predictions be the same as the predictions\n",
        "interpreter_predictions = np.reshape(interpreter_predictions, predictions.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-eb9c32d01d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Make the shape of the y_test be the same as the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# Make the shape of the interpreter_predictions be the same as the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0minterpreter_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciEdnWpc1rR5",
        "colab_type": "text"
      },
      "source": [
        "## Plot the Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBsN_bVu1HL",
        "colab_type": "code",
        "outputId": "7a8bb544-3b14-49b5-a3c2-457d494a435f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.clf()\n",
        "plt.title('Test data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted (tensorflow)')\n",
        "############################################################\n",
        "#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\n",
        "script = \"\"#@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}